# ðŸ¤– ML íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

## ë§› ë²¡í„°í™” ëª¨ë¸ (Taste2Vec)

ì»¤í”¼ í…Œì´ìŠ¤íŒ… ê²½í—˜ì„ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì— ìž„ë² ë”©í•˜ëŠ” í•µì‹¬ ëª¨ë¸ìž…ë‹ˆë‹¤.

```python
class Taste2Vec:
    """
    ë§› ê²½í—˜ì„ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì— ìž„ë² ë”©
    Input: ì‚¬ìš©ìžì˜ ë§› ê¸°ë¡ (í…ìŠ¤íŠ¸ + ìˆ˜ì¹˜ + ì»¨í…ìŠ¤íŠ¸)
    Output: 128ì°¨ì› ìž„ë² ë”© ë²¡í„°
    """
    def __init__(self):
        # ì»¤í”¼ íŠ¹í™” BERT ëª¨ë¸ (ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸)
        self.text_encoder = AutoModel.from_pretrained('coffee-bert-base')
        
        # ì»¤í”¼ ê°ì„± ì–´íœ˜ ìž„ë² ë”© ëª¨ë¸
        self.sensory_embedding = CoffeeSensoryEmbedding()
        
        # ìˆ˜ì¹˜ ë°ì´í„° ì¸ì½”ë” (ì¶”ì¶œ ë³€ìˆ˜, ê°•ë„ ë“±)
        self.numerical_encoder = nn.Sequential(
            nn.Linear(20, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 64),
            nn.BatchNorm1d(64)
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ì¸ì½”ë” (ì‹œê°„, ë‚ ì”¨, ìž¥ì†Œ ë“±)
        self.context_encoder = nn.LSTM(
            input_size=10,
            hidden_size=32,
            num_layers=2,
            batch_first=True
        )
        
        # ìµœì¢… ìœµí•© ë ˆì´ì–´
        self.fusion_layer = nn.Linear(224, 128)  # ê°ì„± ìž„ë² ë”© ì¶”ê°€ë¡œ ì°¨ì› ì¦ê°€
    
    def encode(self, taste_record):
        # 1. í…ìŠ¤íŠ¸ ìž„ë² ë”© (ë§› ë…¸íŠ¸, ìžìœ  ë©”ëª¨)
        text_features = self.encode_text(taste_record['notes'])
        
        # 2. ê°ì„± ì–´íœ˜ ìž„ë² ë”©
        sensory_features = self.sensory_embedding.encode(taste_record['notes'])
        
        # 3. ìˆ˜ì¹˜ ìž„ë² ë”© (ê°•ë„, ì¶”ì¶œ ë³€ìˆ˜)
        numerical_features = self.encode_numerical(taste_record['metrics'])
        
        # 4. ì»¨í…ìŠ¤íŠ¸ ìž„ë² ë”© (ì‹œê°„ëŒ€, ë‚ ì”¨, ê¸°ë¶„)
        context_features = self.encode_context(taste_record['context'])
        
        # 5. ë©€í‹°ëª¨ë‹¬ ìœµí•©
        combined = torch.cat([
            text_features,      # 64d
            sensory_features,   # 64d
            numerical_features, # 64d
            context_features    # 32d
        ], dim=1)
        
        # 6. ìµœì¢… ìž„ë² ë”© ë° ì •ê·œí™”
        embedding = self.fusion_layer(combined)
        return F.normalize(embedding, p=2, dim=1)
```

## ì‹¤ì‹œê°„ ë¶„ì„ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Edge Computing Layer"
        A[ëª¨ë°”ì¼ ì•±] --> B[TensorFlow Lite]
        B --> C[ì˜¨ë””ë°”ì´ìŠ¤ ì¶”ë¡ ]
        C --> D[ì¦‰ì‹œ í”¼ë“œë°±<br/><50ms]
    end
    
    subgraph "Stream Processing Layer"
        A --> E[Kafka Stream]
        E --> F[Flink ì²˜ë¦¬]
        F --> G[ì‹¤ì‹œê°„ ì§‘ê³„]
        G --> H[êµ¬ë… íŒ¨í„´ ë¶„ì„]
    end
    
    subgraph "Batch Processing Layer"
        G --> I[Spark ë°°ì¹˜]
        I --> J[ëª¨ë¸ ìž¬í•™ìŠµ]
        J --> K[êµ¬ë… íë ˆì´ì…˜ ìµœì í™”]
        K --> L[ëª¨ë¸ ì—…ë°ì´íŠ¸]
    end
    
    subgraph "Serving Layer"
        L --> M[Model Registry]
        M --> N[A/B í…ŒìŠ¤íŠ¸]
        N --> B
        N --> O[Cloud ì¶”ë¡ ]
    end
    
    D --> P[ì‚¬ìš©ìž UI]
    O --> P
    H --> Q[íë ˆì´ì…˜ ì—”ì§„]
    Q --> P
```

## ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì²˜ë¦¬

### 1. í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
```python
class TextEncoder:
    """ì»¤í”¼ íŠ¹í™” í…ìŠ¤íŠ¸ ì¸ì½”ë”"""
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained('coffee-bert-base')
        self.model = AutoModel.from_pretrained('coffee-bert-base')
        
    def encode_text(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ 64ì°¨ì› ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        inputs = self.tokenizer(
            text, 
            return_tensors='pt',
            padding=True,
            truncation=True,
            max_length=512
        )
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            # CLS í† í°ì˜ ìž„ë² ë”© ì‚¬ìš©
            text_embedding = outputs.last_hidden_state[:, 0, :]
            
        return text_embedding
```

### 2. ìˆ˜ì¹˜ ë°ì´í„° ì²˜ë¦¬
```python
class NumericalEncoder:
    """ì¶”ì¶œ ë³€ìˆ˜ì™€ ê°•ë„ ë“± ìˆ˜ì¹˜ ë°ì´í„° ì¸ì½”ë”"""
    def __init__(self):
        self.scaler = StandardScaler()
        self.encoder = nn.Sequential(
            nn.Linear(20, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 64),
            nn.BatchNorm1d(64)
        )
    
    def encode_numerical(self, metrics):
        """ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ 64ì°¨ì› ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        # ìž…ë ¥ ë³€ìˆ˜ë“¤
        features = [
            metrics.get('temperature', 0),      # ì¶”ì¶œ ì˜¨ë„
            metrics.get('grind_size', 0),       # ë¶„ì‡„ë„
            metrics.get('brew_ratio', 0),       # ì¶”ì¶œ ë¹„ìœ¨
            metrics.get('brew_time', 0),        # ì¶”ì¶œ ì‹œê°„
            metrics.get('acidity', 0),          # ì‚°ë¯¸ ê°•ë„
            metrics.get('sweetness', 0),        # ë‹¨ë§› ê°•ë„
            metrics.get('bitterness', 0),       # ì“´ë§› ê°•ë„
            metrics.get('body', 0),             # ë°”ë””ê°
            metrics.get('aftertaste', 0),       # í›„ë¯¸
            metrics.get('balance', 0),          # ê· í˜•ê°
            # ... ì¶”ê°€ ë³€ìˆ˜ë“¤
        ]
        
        # ì •ê·œí™” ë° ì¸ì½”ë”©
        features_tensor = torch.tensor(features, dtype=torch.float32)
        features_normalized = self.scaler.transform(features_tensor.unsqueeze(0))
        
        return self.encoder(features_normalized)
```

### 3. ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
```python
class ContextEncoder:
    """ì‹œê°„, ë‚ ì”¨, ê¸°ë¶„ ë“± ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¸ì½”ë”"""
    def __init__(self):
        self.lstm = nn.LSTM(
            input_size=10,
            hidden_size=32,
            num_layers=2,
            batch_first=True
        )
        
    def encode_context(self, context):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ 32ì°¨ì› ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        # ì‹œê³„ì—´ ì»¨í…ìŠ¤íŠ¸ íŠ¹ì„±
        context_sequence = [
            context.get('hour_of_day', 0) / 24,         # ì‹œê°„ëŒ€ (0-1)
            context.get('day_of_week', 0) / 7,          # ìš”ì¼ (0-1)
            context.get('weather_temp', 20) / 40,       # ê¸°ì˜¨ (ì •ê·œí™”)
            context.get('humidity', 50) / 100,          # ìŠµë„ (0-1)
            context.get('mood_score', 5) / 10,          # ê¸°ë¶„ ì ìˆ˜ (0-1)
            context.get('stress_level', 5) / 10,        # ìŠ¤íŠ¸ë ˆìŠ¤ (0-1)
            context.get('energy_level', 5) / 10,        # ì—ë„ˆì§€ (0-1)
            context.get('hunger_level', 5) / 10,        # ë°°ê³ í”” (0-1)
            context.get('social_setting', 0),           # ì‚¬íšŒì  ìƒí™© (ì›í•«)
            context.get('location_type', 0)             # ìž¥ì†Œ ìœ í˜• (ì›í•«)
        ]
        
        # LSTMìœ¼ë¡œ ì‹œí€€ìŠ¤ ì¸ì½”ë”©
        context_tensor = torch.tensor(context_sequence, dtype=torch.float32)
        context_tensor = context_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, 10)
        
        lstm_out, (hidden, cell) = self.lstm(context_tensor)
        return hidden[-1]  # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ hidden state ì‚¬ìš©
```

## ì˜¨ë¼ì¸ í•™ìŠµ ì‹œìŠ¤í…œ

```python
class OnlineLearningSystem:
    """ì‹¤ì‹œê°„ ì‚¬ìš©ìž í”¼ë“œë°±ì„ í†µí•œ ì˜¨ë¼ì¸ í•™ìŠµ"""
    def __init__(self):
        self.taste2vec = Taste2Vec()
        self.optimizer = AdamW(self.taste2vec.parameters(), lr=1e-4)
        self.replay_buffer = ReplayBuffer(max_size=10000)
        
    def update_from_feedback(self, user_id, taste_record, feedback):
        """ì‚¬ìš©ìž í”¼ë“œë°±ìœ¼ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        # 1. í˜„ìž¬ ìž„ë² ë”© ìƒì„±
        current_embedding = self.taste2vec.encode(taste_record)
        
        # 2. í”¼ë“œë°± ê¸°ë°˜ íƒ€ê²Ÿ ìž„ë² ë”© ê³„ì‚°
        target_embedding = self._calculate_target_from_feedback(
            current_embedding, feedback
        )
        
        # 3. ì†ì‹¤ ê³„ì‚° ë° ë°±í”„ë¡œíŒŒê²Œì´ì…˜
        loss = F.mse_loss(current_embedding, target_embedding)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        # 4. ë¦¬í”Œë ˆì´ ë²„í¼ì— ì €ìž¥
        self.replay_buffer.add(taste_record, feedback, target_embedding)
        
        # 5. ì£¼ê¸°ì ìœ¼ë¡œ ë¦¬í”Œë ˆì´ ë²„í¼ì—ì„œ ë°°ì¹˜ í•™ìŠµ
        if len(self.replay_buffer) > 100:
            self._replay_learning()
    
    def _calculate_target_from_feedback(self, current_embedding, feedback):
        """í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ íƒ€ê²Ÿ ìž„ë² ë”© ê³„ì‚°"""
        if feedback['liked']:
            # ê¸ì • í”¼ë“œë°±: í˜„ìž¬ ìž„ë² ë”© ê°•í™”
            return current_embedding * 1.1
        else:
            # ë¶€ì • í”¼ë“œë°±: ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì¡°ì •
            return current_embedding * 0.9
```

## ëª¨ë¸ ë°°í¬ ë° A/B í…ŒìŠ¤íŠ¸

```python
class ModelServingSystem:
    """ëª¨ë¸ ë°°í¬ ë° A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ"""
    def __init__(self):
        self.model_registry = ModelRegistry()
        self.ab_tester = ABTester()
        self.performance_monitor = PerformanceMonitor()
        
    def deploy_model(self, model_version, traffic_percentage=10):
        """ìƒˆ ëª¨ë¸ ë²„ì „ ì ì§„ì  ë°°í¬"""
        # 1. ëª¨ë¸ ë“±ë¡
        self.model_registry.register(model_version)
        
        # 2. A/B í…ŒìŠ¤íŠ¸ ì„¤ì •
        self.ab_tester.create_experiment(
            name=f"taste2vec_v{model_version}",
            control_model="current_production",
            treatment_model=f"v{model_version}",
            traffic_split={
                "control": 100 - traffic_percentage,
                "treatment": traffic_percentage
            },
            metrics=[
                "recommendation_ctr",
                "user_satisfaction",
                "subscription_retention"
            ]
        )
        
        # 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìž‘
        self.performance_monitor.start_monitoring(model_version)
        
    def evaluate_experiment(self, experiment_name):
        """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‰ê°€"""
        results = self.ab_tester.get_results(experiment_name)
        
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì •
        significance = self._statistical_test(results)
        
        if significance['is_significant'] and significance['improvement'] > 0.05:
            return "promote_to_production"
        elif significance['is_significant'] and significance['improvement'] < -0.05:
            return "rollback"
        else:
            return "continue_experiment"
```

## ì£¼ìš” íŠ¹ì§•

### 1. **ë©€í‹°ëª¨ë‹¬ í•™ìŠµ**
- í…ìŠ¤íŠ¸ (ë§› í‘œí˜„, ê°ì„± ì–´íœ˜, ë¹„ìœ )
- ìˆ˜ì¹˜ (ê°•ë„, ì¶”ì¶œ ë³€ìˆ˜)
- ì»¨í…ìŠ¤íŠ¸ (ì‹œê°„, ë‚ ì”¨, ê¸°ë¶„)
- êµ¬ë… ë°ì´í„° (êµ¬ë… ì´ë ¥, í”¼ë“œë°±, Lab ì‚¬ìš© íŒ¨í„´)
- ì´ ëª¨ë“  ê²ƒì„ í†µí•©í•˜ì—¬ 128ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„

### 2. **ì‹¤ì‹œê°„ ì²˜ë¦¬ ëŠ¥ë ¥**
- ì˜¨ë””ë°”ì´ìŠ¤ ì¶”ë¡ ìœ¼ë¡œ 50ms ì´ë‚´ ì‘ë‹µ
- ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¡œ ì‹¤ì‹œê°„ íŒ¨í„´ ë¶„ì„
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì£¼ê¸°ì  ëª¨ë¸ ì—…ë°ì´íŠ¸

### 3. **ì˜¨ë¼ì¸ í•™ìŠµ**
- ì‚¬ìš©ìž í”¼ë“œë°±ì„ ì¦‰ì‹œ ëª¨ë¸ì— ë°˜ì˜
- ë¦¬í”Œë ˆì´ ë²„í¼ë¥¼ í†µí•œ ì•ˆì •ì  í•™ìŠµ
- ì ì§„ì  ê°œì¸í™” ê°•í™”

### 4. **ì•ˆì „í•œ ëª¨ë¸ ë°°í¬**
- A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì ì§„ì  ë°°í¬
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ìžë™ ë¡¤ë°± ì‹œìŠ¤í…œ

### 5. **í™•ìž¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê¸°ë°˜ ì„¤ê³„
- ìˆ˜í‰ì  í™•ìž¥ ì§€ì›
- ëª¨ë“ˆë³„ ë…ë¦½ì  ì—…ë°ì´íŠ¸ ê°€ëŠ¥